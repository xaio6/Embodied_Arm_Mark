"""
AI SDK å®Œæ•´åŠŸèƒ½æµ‹è¯•å·¥å…·
ç”¨æˆ·å¯ä»¥é€‰æ‹©æµ‹è¯•ä¸åŒçš„LLMåŠŸèƒ½
"""

import asyncio
import os
import sys

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° python path
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from Embodied_SDK.ai import AISDK


class LLMTester:
    """LLMåŠŸèƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.sdk = AISDK()
        self.test_prompts = {
            'basic': [
                "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±",
                "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
                "è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½"
            ],
            'creative': [
                "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—",
                "ç¼–ä¸€ä¸ªå…³äºå°çŒ«çš„æ•…äº‹",
                "è®¾è®¡ä¸€ä¸ªåˆ›æ–°çš„æ‰‹æœºåº”ç”¨æƒ³æ³•"
            ],
            'analytical': [
                "åˆ†æä¸€ä¸‹ç”µå•†è¡Œä¸šçš„å‘å±•è¶‹åŠ¿",
                "æ¯”è¾ƒPythonå’ŒJavaç¼–ç¨‹è¯­è¨€çš„ä¼˜ç¼ºç‚¹",
                "è§£é‡ŠåŒºå—é“¾æŠ€æœ¯çš„å·¥ä½œåŸç†"
            ],
            'conversation': [
                "æˆ‘å«å¼ ä¸‰ï¼Œä»Šå¹´25å²ï¼Œæ˜¯ä¸€åç¨‹åºå‘˜",
                "æˆ‘çš„å·¥ä½œæ˜¯ä»€ä¹ˆï¼Ÿ",
                "æˆ‘å¤šå°‘å²äº†ï¼Ÿ"
            ],
            'coding': [
                "å†™ä¸€ä¸ªPythonå‡½æ•°è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—",
                "è§£é‡Šè¿™æ®µä»£ç çš„ä½œç”¨ï¼šfor i in range(10): print(i)",
                "å¦‚ä½•ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ï¼Ÿ"
            ]
        }
    
    def show_menu(self):
        """æ˜¾ç¤ºä¸»èœå•"""
        print("\n" + "="*60)
        print("ğŸš€ AI SDK LLMåŠŸèƒ½æµ‹è¯•å·¥å…·")
        print("="*60)
        print("è¯·é€‰æ‹©è¦æµ‹è¯•çš„åŠŸèƒ½ï¼š")
        print()
        print("1ï¸âƒ£  åŸºç¡€å¯¹è¯æµ‹è¯•")
        print("2ï¸âƒ£  æµå¼è¾“å‡ºæµ‹è¯•")
        print("3ï¸âƒ£  ä¸Šä¸‹æ–‡å¯¹è¯æµ‹è¯•")
        print("4ï¸âƒ£  å¤šä¼šè¯ç®¡ç†æµ‹è¯•")
        print("5ï¸âƒ£  å¼‚æ­¥è°ƒç”¨æµ‹è¯•")
        print("6ï¸âƒ£  å‚æ•°è°ƒä¼˜æµ‹è¯•")
        print("7ï¸âƒ£  æä¾›å•†å¯¹æ¯”æµ‹è¯•")
        print("8ï¸âƒ£  åˆ›æ„ç”Ÿæˆæµ‹è¯•")
        print("9ï¸âƒ£  ä»£ç ç”Ÿæˆæµ‹è¯•")
        print("ğŸ”Ÿ  åˆ†ææ¨ç†æµ‹è¯•")
        print("1ï¸âƒ£1ï¸âƒ£ å‹åŠ›æµ‹è¯•")
        print("1ï¸âƒ£2ï¸âƒ£ ç»¼åˆåŠŸèƒ½æ¼”ç¤º")
        print("1ï¸âƒ£3ï¸âƒ£ è‡ªå®šä¹‰æµ‹è¯•")
        print("0ï¸âƒ£  é€€å‡º")
        print("="*60)
    
    def test_basic_chat(self):
        """æµ‹è¯•åŸºç¡€å¯¹è¯åŠŸèƒ½"""
        print("\nğŸ¯ åŸºç¡€å¯¹è¯æµ‹è¯•")
        print("-" * 40)
        
        for i, prompt in enumerate(self.test_prompts['basic'], 1):
            print(f"\nğŸ“ æµ‹è¯• {i}/3: {prompt}")
            try:
                response = self.sdk.chat(
                    prompt=prompt,
                    model="qwen-turbo",
                    temperature=0.7,
                    max_tokens=200
                )
                print(f"ğŸ¤– å›å¤: {response['choices'][0]['message']['content']}")
                print(f"ğŸ“Š Tokenä½¿ç”¨: {response.get('usage', {})}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")
            
            input("\næŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...")
    
    def test_stream_chat(self):
        """æµ‹è¯•æµå¼è¾“å‡ºåŠŸèƒ½"""
        print("\nğŸŒŠ æµå¼è¾“å‡ºæµ‹è¯•")
        print("-" * 40)
        
        prompts = [
            "è¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ çš„å‘å±•å†ç¨‹",
            "å†™ä¸€ä¸ªå…³äºæœªæ¥ç§‘æŠ€çš„çŸ­æ–‡",
            "è§£é‡Šæ·±åº¦å­¦ä¹ çš„åŸºæœ¬åŸç†"
        ]
        
        for i, prompt in enumerate(prompts, 1):
            print(f"\nğŸ“ æµå¼æµ‹è¯• {i}/3: {prompt}")
            print("ğŸ¤– å®æ—¶å›å¤: ", end="", flush=True)
            
            try:
                full_content = ""
                for chunk in self.sdk.chat(
                    prompt=prompt,
                    model="qwen-turbo",
                    stream=True,
                    temperature=0.8,
                    max_tokens=300
                ):
                    content = chunk['choices'][0]['delta']['content']
                    print(content, end="", flush=True)
                    full_content += content
                
                print(f"\nğŸ“ æ€»å­—ç¬¦æ•°: {len(full_content)}")
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {e}")
            
            input("\næŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...")
    
    def test_context_chat(self):
        """æµ‹è¯•ä¸Šä¸‹æ–‡å¯¹è¯åŠŸèƒ½"""
        print("\nğŸ’¬ ä¸Šä¸‹æ–‡å¯¹è¯æµ‹è¯•")
        print("-" * 40)
        
        # æ¸…ç©ºå†å²è®°å½•
        self.sdk.clear_conversation_history()
        
        conversation_flow = [
            ("æˆ‘å«ææ˜ï¼Œæ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆ", "å»ºç«‹èº«ä»½ä¿¡æ¯"),
            ("æˆ‘åœ¨åŒ—äº¬å·¥ä½œ", "æ·»åŠ åœ°ç†ä¿¡æ¯"),
            ("æˆ‘å–œæ¬¢ç¼–ç¨‹å’Œé˜…è¯»", "æ·»åŠ å…´è¶£çˆ±å¥½"),
            ("æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ", "æµ‹è¯•å§“åè®°å¿†"),
            ("æˆ‘åœ¨å“ªé‡Œå·¥ä½œï¼Ÿ", "æµ‹è¯•åœ°ç‚¹è®°å¿†"),
            ("æˆ‘çš„çˆ±å¥½æ˜¯ä»€ä¹ˆï¼Ÿ", "æµ‹è¯•å…´è¶£è®°å¿†"),
            ("æ ¹æ®æˆ‘çš„ä¿¡æ¯ï¼Œæ¨èä¸€äº›é€‚åˆæˆ‘çš„ä¹¦ç±", "ç»¼åˆä¿¡æ¯åº”ç”¨")
        ]
        
        for i, (prompt, purpose) in enumerate(conversation_flow, 1):
            print(f"\nğŸ“ æ­¥éª¤ {i}/7 ({purpose}): {prompt}")
            try:
                response = self.sdk.chat(
                    prompt=prompt,
                    model="qwen-turbo",
                    use_context=True,
                    temperature=0.7,
                    max_tokens=150
                )
                print(f"ğŸ¤– å›å¤: {response['choices'][0]['message']['content']}")
                
                # æ˜¾ç¤ºå½“å‰å†å²è®°å½•æ•°é‡
                history = self.sdk.get_conversation_history()
                print(f"ğŸ“š å†å²è®°å½•æ•°é‡: {len(history)}")
                
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")
            
            if i < len(conversation_flow):
                input("\næŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€æ­¥...")
    
    def test_multi_session(self):
        """æµ‹è¯•å¤šä¼šè¯ç®¡ç†åŠŸèƒ½"""
        print("\nğŸ‘¥ å¤šä¼šè¯ç®¡ç†æµ‹è¯•")
        print("-" * 40)
        
        # æ¸…ç©ºæ‰€æœ‰å†å²
        self.sdk.clear_conversation_history()
        
        # ç”¨æˆ·Açš„å¯¹è¯åœºæ™¯
        print("\nğŸ”µ ç”¨æˆ·A (å­¦ç”Ÿ) çš„å¯¹è¯:")
        user_a_prompts = [
            "æˆ‘æ˜¯ä¸€åå¤§å­¦ç”Ÿï¼Œæ­£åœ¨å­¦ä¹ è®¡ç®—æœºç§‘å­¦",
            "æˆ‘éœ€è¦å­¦ä¹ å“ªäº›ç¼–ç¨‹è¯­è¨€ï¼Ÿ",
            "æ¨èä¸€äº›é€‚åˆåˆå­¦è€…çš„é¡¹ç›®"
        ]
        
        for prompt in user_a_prompts:
            print(f"ğŸ‘¤ ç”¨æˆ·A: {prompt}")
            try:
                response = self.sdk.chat(
                    prompt=prompt,
                    model="qwen-turbo",
                    use_context=True,
                    session_id="student_user",
                    temperature=0.7,
                    max_tokens=150
                )
                print(f"ğŸ¤– å›å¤: {response['choices'][0]['message']['content']}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")
        
        # ç”¨æˆ·Bçš„å¯¹è¯åœºæ™¯
        print("\nğŸŸ¢ ç”¨æˆ·B (åˆ›ä¸šè€…) çš„å¯¹è¯:")
        user_b_prompts = [
            "æˆ‘æ˜¯ä¸€ååˆ›ä¸šè€…ï¼Œæ­£åœ¨å¼€å‘ä¸€ä¸ªç”µå•†å¹³å°",
            "æˆ‘éœ€è¦å…³æ³¨å“ªäº›æŠ€æœ¯æ ˆï¼Ÿ",
            "å¦‚ä½•è¿›è¡Œå¸‚åœºæ¨å¹¿ï¼Ÿ"
        ]
        
        for prompt in user_b_prompts:
            print(f"ğŸ‘¤ ç”¨æˆ·B: {prompt}")
            try:
                response = self.sdk.chat(
                    prompt=prompt,
                    model="qwen-turbo",
                    use_context=True,
                    session_id="entrepreneur_user",
                    temperature=0.7,
                    max_tokens=150
                )
                print(f"ğŸ¤– å›å¤: {response['choices'][0]['message']['content']}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")
        
        # æ˜¾ç¤ºä¼šè¯éš”ç¦»æ•ˆæœ
        print("\nğŸ“Š ä¼šè¯éš”ç¦»éªŒè¯:")
        history_a = self.sdk.get_conversation_history("student_user")
        history_b = self.sdk.get_conversation_history("entrepreneur_user")
        print(f"ç”¨æˆ·Aå†å²è®°å½•æ•°é‡: {len(history_a)}")
        print(f"ç”¨æˆ·Bå†å²è®°å½•æ•°é‡: {len(history_b)}")
    
    async def test_async_chat(self):
        """æµ‹è¯•å¼‚æ­¥è°ƒç”¨åŠŸèƒ½"""
        print("\nâš¡ å¼‚æ­¥è°ƒç”¨æµ‹è¯•")
        print("-" * 40)
        
        prompts = [
            "è§£é‡Šä»€ä¹ˆæ˜¯äº‘è®¡ç®—",
            "ä»‹ç»äººå·¥æ™ºèƒ½çš„åº”ç”¨é¢†åŸŸ",
            "åˆ†æå¤§æ•°æ®çš„å‘å±•è¶‹åŠ¿"
        ]
        
        print("ğŸš€ å¹¶å‘æ‰§è¡Œ3ä¸ªå¼‚æ­¥è¯·æ±‚...")
        
        try:
            # å¹¶å‘æ‰§è¡Œå¤šä¸ªå¼‚æ­¥è¯·æ±‚
            tasks = []
            for i, prompt in enumerate(prompts, 1):
                task = self.sdk.chat(
                    prompt=prompt,
                    model="qwen-turbo",
                    async_mode=True,
                    temperature=0.7,
                    max_tokens=200
                )
                tasks.append((i, prompt, task))
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for i, prompt, task in tasks:
                response = await task
                print(f"\nğŸ“ ä»»åŠ¡ {i}: {prompt}")
                print(f"ğŸ¤– å›å¤: {response['choices'][0]['message']['content']}")
        
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
    
    def test_parameter_tuning(self):
        """æµ‹è¯•å‚æ•°è°ƒä¼˜åŠŸèƒ½"""
        print("\nâš™ï¸ å‚æ•°è°ƒä¼˜æµ‹è¯•")
        print("-" * 40)
        
        prompt = "å†™ä¸€é¦–å…³äºç§‹å¤©çš„è¯—"
        
        # æµ‹è¯•ä¸åŒçš„temperatureå€¼
        temperatures = [0.1, 0.5, 0.9, 1.5]
        
        for temp in temperatures:
            print(f"\nğŸŒ¡ï¸ Temperature = {temp}")
            try:
                response = self.sdk.chat(
                    prompt=prompt,
                    model="qwen-turbo",
                    temperature=temp,
                    max_tokens=200,
                    top_p=0.8
                )
                print(f"ğŸ¤– å›å¤: {response['choices'][0]['message']['content']}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")
            
            input("\næŒ‰å›è½¦æµ‹è¯•ä¸‹ä¸€ä¸ªå‚æ•°...")
    
    def test_provider_comparison(self):
        """æµ‹è¯•æä¾›å•†å¯¹æ¯”"""
        print("\nğŸ­ æä¾›å•†å¯¹æ¯”æµ‹è¯•")
        print("-" * 40)
        
        prompt = "è¯·è§£é‡Šä»€ä¹ˆæ˜¯é‡å­è®¡ç®—"
        providers = [
            ("alibaba", "qwen-turbo"),
            ("deepseek", "deepseek-chat")
        ]
        
        for provider, model in providers:
            print(f"\nğŸ”§ æµ‹è¯• {provider.upper()} - {model}")
            try:
                response = self.sdk.chat(
                    provider=provider,
                    model=model,
                    prompt=prompt,
                    temperature=0.7,
                    max_tokens=200
                )
                print(f"ğŸ¤– å›å¤: {response['choices'][0]['message']['content']}")
                print(f"ğŸ“Š Tokenä½¿ç”¨: {response.get('usage', {})}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")
            
            input("\næŒ‰å›è½¦æµ‹è¯•ä¸‹ä¸€ä¸ªæä¾›å•†...")
    
    def test_creative_generation(self):
        """æµ‹è¯•åˆ›æ„ç”ŸæˆåŠŸèƒ½"""
        print("\nğŸ¨ åˆ›æ„ç”Ÿæˆæµ‹è¯•")
        print("-" * 40)
        
        for i, prompt in enumerate(self.test_prompts['creative'], 1):
            print(f"\nğŸ“ åˆ›æ„æµ‹è¯• {i}/3: {prompt}")
            try:
                response = self.sdk.chat(
                    prompt=prompt,
                    model="qwen-turbo",
                    temperature=1.0,  # é«˜åˆ›é€ æ€§
                    max_tokens=300,
                    top_p=0.9
                )
                print(f"ğŸ¤– åˆ›æ„å›å¤: {response['choices'][0]['message']['content']}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")
            
            input("\næŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ªåˆ›æ„æµ‹è¯•...")
    
    def test_code_generation(self):
        """æµ‹è¯•ä»£ç ç”ŸæˆåŠŸèƒ½"""
        print("\nğŸ’» ä»£ç ç”Ÿæˆæµ‹è¯•")
        print("-" * 40)
        
        for i, prompt in enumerate(self.test_prompts['coding'], 1):
            print(f"\nğŸ“ ä»£ç æµ‹è¯• {i}/3: {prompt}")
            try:
                response = self.sdk.chat(
                    prompt=prompt,
                    model="qwen-turbo",
                    temperature=0.3,  # ä½åˆ›é€ æ€§ï¼Œæ›´å‡†ç¡®
                    max_tokens=400
                )
                print(f"ğŸ¤– ä»£ç å›å¤: {response['choices'][0]['message']['content']}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")
            
            input("\næŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ªä»£ç æµ‹è¯•...")
    
    def test_analytical_reasoning(self):
        """æµ‹è¯•åˆ†ææ¨ç†åŠŸèƒ½"""
        print("\nğŸ§  åˆ†ææ¨ç†æµ‹è¯•")
        print("-" * 40)
        
        for i, prompt in enumerate(self.test_prompts['analytical'], 1):
            print(f"\nğŸ“ åˆ†ææµ‹è¯• {i}/3: {prompt}")
            try:
                response = self.sdk.chat(
                    prompt=prompt,
                    model="qwen-turbo",
                    temperature=0.5,
                    max_tokens=400
                )
                print(f"ğŸ¤– åˆ†æå›å¤: {response['choices'][0]['message']['content']}")
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")
            
            input("\næŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ªåˆ†ææµ‹è¯•...")
    
    def test_stress_test(self):
        """å‹åŠ›æµ‹è¯•"""
        print("\nğŸ”¥ å‹åŠ›æµ‹è¯•")
        print("-" * 40)
        
        print("æ‰§è¡Œ10æ¬¡è¿ç»­è¯·æ±‚æµ‹è¯•...")
        
        success_count = 0
        error_count = 0
        
        for i in range(1, 11):
            print(f"\nğŸ“ è¯·æ±‚ {i}/10")
            try:
                response = self.sdk.chat(
                    prompt=f"è¿™æ˜¯ç¬¬{i}æ¬¡æµ‹è¯•è¯·æ±‚ï¼Œè¯·ç®€å•å›å¤",
                    model="qwen-turbo",
                    temperature=0.7,
                    max_tokens=50
                )
                print(f"âœ… æˆåŠŸ: {response['choices'][0]['message']['content']}")
                success_count += 1
            except Exception as e:
                print(f"âŒ å¤±è´¥: {e}")
                error_count += 1
        
        print(f"\nğŸ“Š å‹åŠ›æµ‹è¯•ç»“æœ:")
        print(f"æˆåŠŸ: {success_count}/10")
        print(f"å¤±è´¥: {error_count}/10")
        print(f"æˆåŠŸç‡: {success_count/10*100:.1f}%")
    
    def test_comprehensive_demo(self):
        """ç»¼åˆåŠŸèƒ½æ¼”ç¤º"""
        print("\nğŸª ç»¼åˆåŠŸèƒ½æ¼”ç¤º")
        print("-" * 40)
        
        print("ğŸ¯ æ¼”ç¤ºåœºæ™¯ï¼šAIåŠ©æ‰‹å¸®åŠ©ç”¨æˆ·è§„åˆ’å­¦ä¹ è·¯å¾„")
        
        # æ¸…ç©ºå†å²
        self.sdk.clear_conversation_history()
        
        conversation = [
            "æˆ‘æƒ³å­¦ä¹ äººå·¥æ™ºèƒ½ï¼Œä½†æ˜¯æˆ‘æ˜¯é›¶åŸºç¡€",
            "æˆ‘åº”è¯¥ä»å“ªäº›æ•°å­¦çŸ¥è¯†å¼€å§‹å­¦ï¼Ÿ",
            "æ¨èä¸€äº›å…¥é—¨çš„ç¼–ç¨‹è¯­è¨€",
            "åˆ¶å®šä¸€ä¸ª3ä¸ªæœˆçš„å­¦ä¹ è®¡åˆ’"
        ]
        
        for i, prompt in enumerate(conversation, 1):
            print(f"\nğŸ‘¤ ç”¨æˆ·: {prompt}")
            
            # ä½¿ç”¨æµå¼è¾“å‡º + ä¸Šä¸‹æ–‡
            print("ğŸ¤– AIåŠ©æ‰‹: ", end="", flush=True)
            try:
                for chunk in self.sdk.chat(
                    prompt=prompt,
                    model="qwen-turbo",
                    stream=True,
                    use_context=True,
                    session_id="learning_plan",
                    temperature=0.7,
                    max_tokens=300
                ):
                    content = chunk['choices'][0]['delta']['content']
                    print(content, end="", flush=True)
                print("\n")
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {e}")
            
            if i < len(conversation):
                input("æŒ‰å›è½¦ç»§ç»­å¯¹è¯...")
    
    def test_custom(self):
        """è‡ªå®šä¹‰æµ‹è¯•"""
        print("\nğŸ› ï¸ è‡ªå®šä¹‰æµ‹è¯•")
        print("-" * 40)
        
        while True:
            print("\nè¯·é€‰æ‹©è‡ªå®šä¹‰æµ‹è¯•é€‰é¡¹:")
            print("1. è‡ªå®šä¹‰æç¤ºè¯æµ‹è¯•")
            print("2. è‡ªå®šä¹‰å‚æ•°æµ‹è¯•")
            print("3. è¿”å›ä¸»èœå•")
            
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
            
            if choice == "1":
                prompt = input("\nè¯·è¾“å…¥è‡ªå®šä¹‰æç¤ºè¯: ").strip()
                if prompt:
                    try:
                        response = self.sdk.chat(
                            prompt=prompt,
                            model="qwen-turbo",
                            temperature=0.7,
                            max_tokens=300
                        )
                        print(f"\nğŸ¤– å›å¤: {response['choices'][0]['message']['content']}")
                    except Exception as e:
                        print(f"âŒ é”™è¯¯: {e}")
            
            elif choice == "2":
                prompt = input("\nè¯·è¾“å…¥æç¤ºè¯: ").strip()
                if prompt:
                    try:
                        temp = float(input("è¯·è¾“å…¥temperature (0.0-2.0): ") or "0.7")
                        max_tokens = int(input("è¯·è¾“å…¥max_tokens (1-2000): ") or "300")
                        top_p = float(input("è¯·è¾“å…¥top_p (0.0-1.0): ") or "0.8")
                        
                        response = self.sdk.chat(
                            prompt=prompt,
                            model="qwen-turbo",
                            temperature=temp,
                            max_tokens=max_tokens,
                            top_p=top_p
                        )
                        print(f"\nğŸ¤– å›å¤: {response['choices'][0]['message']['content']}")
                    except Exception as e:
                        print(f"âŒ é”™è¯¯: {e}")
            
            elif choice == "3":
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def run(self):
        """è¿è¡Œæµ‹è¯•å·¥å…·"""
        while True:
            self.show_menu()
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-13): ").strip()
            
            try:
                if choice == "0":
                    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨AI SDKæµ‹è¯•å·¥å…·ï¼")
                    break
                elif choice == "1":
                    self.test_basic_chat()
                elif choice == "2":
                    self.test_stream_chat()
                elif choice == "3":
                    self.test_context_chat()
                elif choice == "4":
                    self.test_multi_session()
                elif choice == "5":
                    asyncio.run(self.test_async_chat())
                elif choice == "6":
                    self.test_parameter_tuning()
                elif choice == "7":
                    self.test_provider_comparison()
                elif choice == "8":
                    self.test_creative_generation()
                elif choice == "9":
                    self.test_code_generation()
                elif choice == "10":
                    self.test_analytical_reasoning()
                elif choice == "11":
                    self.test_stress_test()
                elif choice == "12":
                    self.test_comprehensive_demo()
                elif choice == "13":
                    self.test_custom()
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
            
            except KeyboardInterrupt:
                print("\n\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
            except Exception as e:
                print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            
            if choice != "0":
                input("\næŒ‰å›è½¦è¿”å›ä¸»èœå•...")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ åˆå§‹åŒ–AI SDKæµ‹è¯•å·¥å…·...")
    try:
        tester = LLMTester()
        tester.run()
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶å’Œç½‘ç»œè¿æ¥")

if __name__ == "__main__":
    main() 