"""
AI SDK - å¤šå‚å•†äººå·¥æ™ºèƒ½æœåŠ¡ç»Ÿä¸€è°ƒç”¨æ¡†æ¶

æä¾›ç®€å•æ˜“ç”¨çš„ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒï¼š
- ğŸ¤– å¤šå‚å•†AIæ¨¡å‹è°ƒç”¨ (é˜¿é‡Œäº‘ã€DeepSeekç­‰)
- ğŸ¤ è¯­éŸ³è¯†åˆ« (ASR)
- ğŸŒŠ æµå¼è¾“å‡º
- âš¡ å¼‚æ­¥è°ƒç”¨
- ğŸ’¬ ä¸Šä¸‹æ–‡å¯¹è¯
- ğŸ‘¥ å¤šä¼šè¯ç®¡ç†
"""

import os
from typing import Iterator, AsyncIterator, Dict, Any, List, Optional, Union, Generator, AsyncGenerator, Tuple
from .core.llm import ChatHandler
from .core.session import ChatSession
from .core.asr import ASRHandler
from .core.tts import TTSHandler
from .core.multimodal import MultiModalHandler
from .core.smart_chat import SmartChatHandler
from .core.smart_chat.multimodal import SmartMultiModalChatHandler
from .core.smart_chat.voice import SmartVoiceChatHandler
from .core.smart_chat.multimodal_voice import SmartMultiModalVoiceChatHandler
from .utils.exceptions import AISDKException, ValidationException, ConfigException
import yaml
import cv2
import numpy as np
import time

__version__ = "1.0.0"
__author__ = "AI SDK Team"

class AISDK:
    """
    AI SDK ä¸»ç±» - å¤šå‚å•†äººå·¥æ™ºèƒ½æœåŠ¡ç»Ÿä¸€è°ƒç”¨æ¡†æ¶
    
    ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ï¼š
    - chat(): ç»Ÿä¸€èŠå¤©æ¥å£ï¼Œé€šè¿‡å‚æ•°æ§åˆ¶æ‰€æœ‰åŠŸèƒ½
    - asr(): ç»Ÿä¸€è¯­éŸ³è¯†åˆ«æ¥å£ï¼Œæ”¯æŒå¤šç§è¯†åˆ«æ¨¡å¼
    - tts(): ç»Ÿä¸€è¯­éŸ³åˆæˆæ¥å£ï¼Œæ”¯æŒå¤šç§åˆæˆæ¨¡å¼
    - multimodal(): ç»Ÿä¸€å¤šæ¨¡æ€æ¥å£ï¼Œæ”¯æŒå›¾åƒå’Œè§†é¢‘ç†è§£
    - smart_chat(): LLM + TTS æ™ºèƒ½å¯¹è¯ï¼Œä¸€é”®å®ç°AIé—®ç­”å¹¶è¯­éŸ³æ’­æ”¾
    - smart_multimodal_chat(): å¤šæ¨¡æ€æ™ºèƒ½å¯¹è¯ï¼Œæ”¯æŒå›¾åƒã€è§†é¢‘ã€è¯­éŸ³ç­‰å¤šç§è¾“å…¥
    - æ”¯æŒæµå¼è¾“å‡ºã€å¼‚æ­¥è°ƒç”¨ã€ä¸Šä¸‹æ–‡å¯¹è¯
    - è‡ªåŠ¨ç®¡ç†ä¼šè¯å’Œå†å²è®°å½•
    
    ğŸ“ ä½¿ç”¨ç¤ºä¾‹ï¼š
        # åŸºç¡€å¯¹è¯
        response = sdk.chat("alibaba", "qwen-turbo", "ä½ å¥½")
        
        # æµå¼è¾“å‡º
        for chunk in sdk.chat("alibaba", "qwen-turbo", "ä½ å¥½", stream=True):
            print(chunk['choices'][0]['delta']['content'], end='')
        
        # ä¸Šä¸‹æ–‡å¯¹è¯
        sdk.chat("alibaba", "qwen-turbo", "æˆ‘å«å¼ ä¸‰", use_context=True)
        sdk.chat("alibaba", "qwen-turbo", "æˆ‘å«ä»€ä¹ˆï¼Ÿ", use_context=True)
        
        # è¯­éŸ³è¯†åˆ«
        result = sdk.asr("alibaba", "file", audio_file="audio.wav")
        result = sdk.asr("alibaba", "microphone", duration=5)
        
        # è¯­éŸ³åˆæˆ
        result = sdk.tts("alibaba", "file", "ä½ å¥½ä¸–ç•Œ", output_file="output.mp3")
        result = sdk.tts("alibaba", "speaker", "ä½ å¥½ä¸–ç•Œ")
        
        # å¤šæ¨¡æ€ç†è§£
        result = sdk.multimodal("alibaba", "image", "æè¿°è¿™å¼ å›¾ç‰‡", image_path="image.jpg")
        result = sdk.multimodal("alibaba", "video", "åˆ†æè¿™ä¸ªè§†é¢‘", video_path="video.mp4")
        
        # æ™ºèƒ½å¯¹è¯ï¼ˆLLM + TTSï¼‰
        result = sdk.smart_chat("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
        result = sdk.smart_chat("è®²ä¸ªæ•…äº‹", tts_mode="file", output_file="story.mp3")
        
        # å¼‚æ­¥è°ƒç”¨
        response = await sdk.chat("alibaba", "qwen-turbo", "ä½ å¥½", async_mode=True)
        result = await sdk.smart_chat("ä½ å¥½", async_mode=True)
    """
    
    def __init__(self, config_path: str = None, config_dict: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–AI SDK
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨config.yaml
            config_dict: é…ç½®å­—å…¸ï¼ˆä¸config_pathäºŒé€‰ä¸€ï¼‰
        """
        # åŠ è½½é…ç½®
        if config_path:
            self.config = self._load_config(config_path)
        elif config_dict:
            self.config = config_dict
        else:
            # ä¼˜å…ˆä»å¤–ç½®ç›®å½•è¯»å–ï¼ˆç”± run_gui è®¾ç½®çš„ç¯å¢ƒå˜é‡ï¼‰
            default_path = os.environ.get('AISDK_CONFIG_PATH')
            if not default_path:
                ext_dir = os.environ.get('HORIZONARM_CONFIG_DIR')
                if ext_dir:
                    default_path = os.path.join(ext_dir, 'aisdk_config.yaml')
            if not default_path:
                default_path = 'config/aisdk_config.yaml'
            try:
                self.config = self._load_config(default_path)
            except Exception as e:
                raise ConfigException(f"æ— æ³•åŠ è½½é»˜è®¤é…ç½®æ–‡ä»¶aisdk_config.yaml: {str(e)}")
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        self.chat_handler = ChatHandler(self.config)
        self.asr_handler = ASRHandler(self.config)
        self.tts_handler = TTSHandler(self.config)
        self.multimodal_handler = MultiModalHandler(self.config)
        self.smart_chat_handler = SmartChatHandler(self)
        self.smart_multimodal_chat_handler = SmartMultiModalChatHandler(self)
        self.smart_voice_chat_handler = SmartVoiceChatHandler(self)
        self.smart_multimodal_voice_chat_handler = SmartMultiModalVoiceChatHandler(self)
        
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config_content = f.read()
            
            # æ›¿æ¢ç¯å¢ƒå˜é‡
            config_content = self._replace_env_vars(config_content)
            
            # è§£æYAML
            config = yaml.safe_load(config_content)
            return config
            
        except FileNotFoundError:
            raise ConfigException(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
        except yaml.YAMLError as e:
            raise ConfigException(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
    
    def _replace_env_vars(self, content: str) -> str:
        """æ›¿æ¢é…ç½®æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡"""
        import re
        import os
        
        # åŒ¹é… ${VAR_NAME:default_value} æ ¼å¼
        pattern = r'\$\{([A-Za-z0-9_]+):?([^}]*)\}'
        
        def replace_var(match):
            var_name = match.group(1)
            default_value = match.group(2)
            return os.getenv(var_name, default_value)
        
        return re.sub(pattern, replace_var, content)
    
    def chat(self, 
             provider: str, 
             model: str, 
             prompt: str,
             stream: bool = False,
             async_mode: bool = False,
             use_context: bool = False,
             session_id: str = None,
             **kwargs) -> Union[Dict[str, Any], Iterator[Dict[str, Any]], AsyncIterator[Dict[str, Any]]]:
        """
        ğŸ¤– ç»Ÿä¸€èŠå¤©æ¥å£ - é€šè¿‡å‚æ•°æ§åˆ¶æ‰€æœ‰åŠŸèƒ½
        
        Args:
            provider: æä¾›å•†åç§° (alibaba, deepseek)
            model: æ¨¡å‹åç§°
            prompt: æç¤ºè¯
            stream: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡ºï¼Œé»˜è®¤False
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œé»˜è®¤False
            use_context: æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡å¯¹è¯ï¼Œé»˜è®¤False
            session_id: ä¼šè¯IDï¼Œå¯ç”¨ä¸Šä¸‹æ–‡æ—¶ä½¿ç”¨ï¼Œä¸æä¾›åˆ™ä½¿ç”¨å…¨å±€å†å²
            **kwargs: å…¶ä»–å‚æ•° (temperature, max_tokens, top_pç­‰)
            
        Returns:
            æ ¹æ®å‚æ•°è¿”å›ä¸åŒç±»å‹çš„ç»“æœï¼š
            - æ™®é€šåŒæ­¥: Dict[str, Any]
            - æµå¼åŒæ­¥: Iterator[Dict[str, Any]]
            - æ™®é€šå¼‚æ­¥: Awaitable[Dict[str, Any]]
            - æµå¼å¼‚æ­¥: AsyncIterator[Dict[str, Any]]
            
        Examples:
            # åŸºç¡€å¯¹è¯
            response = sdk.chat("alibaba", "qwen-turbo", "ä½ å¥½")
            
            # æµå¼è¾“å‡º
            for chunk in sdk.chat("alibaba", "qwen-turbo", "ä½ å¥½", stream=True):
                print(chunk['choices'][0]['delta']['content'], end='')
            
            # å¼‚æ­¥å¯¹è¯
            response = await sdk.chat("alibaba", "qwen-turbo", "ä½ å¥½", async_mode=True)
            
            # å¼‚æ­¥æµå¼
            async for chunk in sdk.chat("alibaba", "qwen-turbo", "ä½ å¥½", stream=True, async_mode=True):
                print(chunk['choices'][0]['delta']['content'], end='')
            
            # ä¸Šä¸‹æ–‡å¯¹è¯
            response1 = sdk.chat("alibaba", "qwen-turbo", "æˆ‘å«å¼ ä¸‰", use_context=True)
            response2 = sdk.chat("alibaba", "qwen-turbo", "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ", use_context=True)
            
            # æŒ‡å®šä¼šè¯çš„ä¸Šä¸‹æ–‡å¯¹è¯
            response = sdk.chat("alibaba", "qwen-turbo", "ä½ å¥½", use_context=True, session_id="user123")
        """
        return self.chat_handler.handle_chat(
            provider, model, prompt, stream, async_mode, use_context, session_id, **kwargs
        )
    
    def asr(self, 
            provider: str, 
            mode: str,
            async_mode: bool = False,
            **kwargs) -> Union[Dict[str, Any], Generator[Dict[str, Any], None, None], AsyncGenerator[Dict[str, Any], None]]:
        """
        ğŸ¤ ç»Ÿä¸€è¯­éŸ³è¯†åˆ«æ¥å£ - é€šè¿‡æ¨¡å¼å‚æ•°æ§åˆ¶ä¸åŒçš„ASRåŠŸèƒ½
        
        Args:
            provider: ASRæä¾›å•†åç§° (ç›®å‰æ”¯æŒ: alibaba)
            mode: è¯†åˆ«æ¨¡å¼ ("file", "microphone", "stream", "keyword")
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œé»˜è®¤False
            **kwargs: å…¶ä»–å‚æ•°ï¼Œæ ¹æ®æ¨¡å¼ä¸åŒè€Œä¸åŒ
            
        Returns:
            æ ¹æ®æ¨¡å¼å’Œasync_modeè¿”å›ä¸åŒç±»å‹çš„ç»“æœ
            
        Examples:
            # æ–‡ä»¶è¯†åˆ«
            result = sdk.asr("alibaba", "file", audio_file="audio.wav")
            
            # éº¦å…‹é£è¯†åˆ«
            result = sdk.asr("alibaba", "microphone", duration=5)
            
            # å®æ—¶è¯†åˆ«
            for result in sdk.asr("alibaba", "stream", audio_stream=stream):
                print(result['text'])
            
            # å…³é”®è¯æ£€æµ‹
            for result in sdk.asr("alibaba", "keyword", keywords=["ä½ å¥½", "å°åŠ©æ‰‹"]):
                if result['success']:
                    print(f"æ£€æµ‹åˆ°: {result['keyword_detected']}")
            
            # å¼‚æ­¥æ–‡ä»¶è¯†åˆ«
            result = await sdk.asr("alibaba", "file", audio_file="audio.wav", async_mode=True)
        """
        if mode == "file":
            audio_file = kwargs.pop('audio_file', None)
            if not audio_file:
                raise ValueError("æ–‡ä»¶è¯†åˆ«æ¨¡å¼éœ€è¦æä¾› audio_file å‚æ•°")
            
            if async_mode:
                return self.asr_handler.recognize_file_async(provider, audio_file, **kwargs)
            else:
                return self.asr_handler.recognize_file(provider, audio_file, **kwargs)
        
        elif mode == "microphone":
            duration = kwargs.pop('duration', 5)
            return self.asr_handler.recognize_microphone(provider, duration, **kwargs)
        
        elif mode == "stream":
            audio_stream = kwargs.pop('audio_stream', None)
            if audio_stream is None:
                raise ValueError("æµå¼è¯†åˆ«æ¨¡å¼éœ€è¦æä¾› audio_stream å‚æ•°")
            
            if async_mode:
                return self.asr_handler.recognize_stream_async(provider, audio_stream, **kwargs)
            else:
                return self.asr_handler.recognize_stream(provider, audio_stream, **kwargs)
        
        elif mode == "keyword":
            keywords = kwargs.pop('keywords', None)
            if not keywords:
                raise ValueError("å…³é”®è¯æ£€æµ‹æ¨¡å¼éœ€è¦æä¾› keywords å‚æ•°")
            
            return self.asr_handler.keyword_spotting(provider, keywords, **kwargs)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ASRæ¨¡å¼: {mode}ï¼Œæ”¯æŒçš„æ¨¡å¼: file, microphone, stream, keyword")

    def tts(self, 
            provider: str, 
            mode: str,
            text: str,
            async_mode: bool = False,
            **kwargs) -> Union[Dict[str, Any], Generator[Dict[str, Any], None, None], AsyncGenerator[Dict[str, Any], None]]:
        """
        ğŸ”Š ç»Ÿä¸€è¯­éŸ³åˆæˆæ¥å£ - é€šè¿‡æ¨¡å¼å‚æ•°æ§åˆ¶ä¸åŒçš„TTSåŠŸèƒ½
        
        Args:
            provider: TTSæä¾›å•†åç§° (ç›®å‰æ”¯æŒ: alibaba)
            mode: åˆæˆæ¨¡å¼ ("file", "speaker", "stream")
            text: è¦åˆæˆçš„æ–‡æœ¬
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œé»˜è®¤False
            **kwargs: å…¶ä»–å‚æ•°ï¼Œæ ¹æ®æ¨¡å¼ä¸åŒè€Œä¸åŒ
            
        Returns:
            æ ¹æ®æ¨¡å¼å’Œasync_modeè¿”å›ä¸åŒç±»å‹çš„ç»“æœ
            
        Examples:
            # ä¿å­˜åˆ°æ–‡ä»¶
            result = sdk.tts("alibaba", "file", "ä½ å¥½ä¸–ç•Œ", output_file="output.mp3")
            
            # æ‰¬å£°å™¨æ’­æ”¾
            result = sdk.tts("alibaba", "speaker", "ä½ å¥½ä¸–ç•Œ")
            
            # æµå¼åˆæˆï¼ˆé…åˆLLMæµå¼è¾“å‡ºï¼‰
            def text_generator():
                yield "ä½ å¥½"
                yield "ä¸–ç•Œ"
            
            for result in sdk.tts("alibaba", "stream", text_generator()):
                print(f"åˆæˆå®Œæˆ: {result['text_chunk']}")
            
            # å¼‚æ­¥åˆæˆ
            result = await sdk.tts("alibaba", "file", "ä½ å¥½ä¸–ç•Œ", 
                                 output_file="output.mp3", async_mode=True)
        """
        if mode == "file":
            output_file = kwargs.pop('output_file', None)
            if not output_file:
                raise ValueError("æ–‡ä»¶æ¨¡å¼éœ€è¦æä¾› output_file å‚æ•°")
            
            if async_mode:
                return self.tts_handler.synthesize_to_file_async(provider, text, output_file, **kwargs)
            else:
                return self.tts_handler.synthesize_to_file(provider, text, output_file, **kwargs)
        
        elif mode == "speaker":
            if async_mode:
                return self.tts_handler.synthesize_to_speaker_async(provider, text, **kwargs)
            else:
                return self.tts_handler.synthesize_to_speaker(provider, text, **kwargs)
        
        elif mode == "stream":
            # å¯¹äºæµå¼æ¨¡å¼ï¼Œtextå‚æ•°åº”è¯¥æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨
            text_stream = text if hasattr(text, '__iter__') and not isinstance(text, str) else [text]
            
            if async_mode:
                return self.tts_handler.synthesize_stream_async(provider, text_stream, **kwargs)
            else:
                return self.tts_handler.synthesize_stream(provider, text_stream, **kwargs)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„TTSæ¨¡å¼: {mode}ï¼Œæ”¯æŒçš„æ¨¡å¼: file, speaker, stream")

    def multimodal(self,
                   provider: str,
                   mode: str,
                   prompt: str,
                   image_path: str = None,
                   video_path: str = None,
                   async_mode: bool = False,
                   **kwargs) -> Dict[str, Any]:
        """
        ğŸ¤–ğŸ¥ ç»Ÿä¸€å¤šæ¨¡æ€æ¥å£ - é€šè¿‡æ¨¡å¼å‚æ•°æ§åˆ¶ä¸åŒçš„å¤šæ¨¡æ€åŠŸèƒ½
        
        Args:
            provider: å¤šæ¨¡æ€æä¾›å•†åç§° (ç›®å‰æ”¯æŒ: alibaba)
            mode: å¤šæ¨¡æ€æ¨¡å¼ ("image", "video", "multiple_images")
            prompt: æç¤ºè¯
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„æˆ–URLï¼ˆimageæ¨¡å¼ä½¿ç”¨ï¼‰
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–URLï¼ˆvideoæ¨¡å¼ä½¿ç”¨ï¼‰
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œé»˜è®¤False
            **kwargs: å…¶ä»–å‚æ•°ï¼Œæ ¹æ®æ¨¡å¼ä¸åŒè€Œä¸åŒ
                - image_paths: å¤šå›¾åƒè·¯å¾„åˆ—è¡¨ï¼ˆmultiple_imagesæ¨¡å¼ä½¿ç”¨ï¼‰
                - model: æ¨¡å‹åç§°ï¼Œé»˜è®¤qwen-vl-max-latest
                - temperature: æ¸©åº¦å‚æ•°
                - max_tokens: æœ€å¤§tokenæ•°
                - fps: è§†é¢‘æŠ½å¸§é¢‘ç‡ï¼ˆvideoæ¨¡å¼ä½¿ç”¨ï¼‰
                
        Returns:
            å¤šæ¨¡æ€ç»“æœå­—å…¸
            
        Examples:
            # å›¾åƒç†è§£
            result = sdk.multimodal("alibaba", "image", "æè¿°è¿™å¼ å›¾ç‰‡", image_path="image.jpg")
            
            # è§†é¢‘åˆ†æ
            result = sdk.multimodal("alibaba", "video", "åˆ†æè¿™ä¸ªè§†é¢‘", video_path="video.mp4")
            
            # å¤šå›¾åƒåˆ†æ
            result = sdk.multimodal("alibaba", "multiple_images", "æ¯”è¾ƒè¿™äº›å›¾ç‰‡", 
                                  image_paths=["img1.jpg", "img2.jpg"])
            
            # å¼‚æ­¥è°ƒç”¨
            result = await sdk.multimodal("alibaba", "image", "æè¿°å›¾ç‰‡", 
                                        image_path="image.jpg", async_mode=True)
        """
        if mode == "image":
            if not image_path:
                raise ValueError("å›¾åƒç†è§£æ¨¡å¼éœ€è¦æä¾› image_path å‚æ•°")
            
            if async_mode:
                return self.multimodal_handler.analyze_image_async(provider, image_path, prompt, **kwargs)
            else:
                return self.multimodal_handler.analyze_image(provider, image_path, prompt, **kwargs)
        
        elif mode == "video":
            if not video_path:
                raise ValueError("è§†é¢‘åˆ†ææ¨¡å¼éœ€è¦æä¾› video_path å‚æ•°")
            
            if async_mode:
                return self.multimodal_handler.analyze_video_async(provider, video_path, prompt, **kwargs)
            else:
                return self.multimodal_handler.analyze_video(provider, video_path, prompt, **kwargs)
        
        elif mode == "multiple_images":
            image_paths = kwargs.pop('image_paths', [])
            if not image_paths:
                raise ValueError("å¤šå›¾åƒåˆ†ææ¨¡å¼éœ€è¦æä¾› image_paths å‚æ•°")
            
            if async_mode:
                return self.multimodal_handler.analyze_multiple_images_async(provider, image_paths, prompt, **kwargs)
            else:
                return self.multimodal_handler.analyze_multiple_images(provider, image_paths, prompt, **kwargs)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¤šæ¨¡æ€æ¨¡å¼: {mode}ï¼Œæ”¯æŒçš„æ¨¡å¼: image, video, multiple_images")

    def smart_chat(self,
                   prompt: str,
                   llm_provider: str = "alibaba",
                   llm_model: str = "qwen-turbo", 
                   tts_provider: str = "alibaba",
                   tts_model: str = "sambert-zhichu-v1",
                   tts_mode: str = "speaker",
                   use_context: bool = False,
                   session_id: str = None,
                   stream_chat: bool = False,
                   async_mode: bool = False,
                   **kwargs) -> Dict[str, Any]:
        """
        ğŸ¤–ğŸ”Š LLM + TTS æ™ºèƒ½å¯¹è¯ - ä¸€é”®å®ç°AIé—®ç­”å¹¶è¯­éŸ³æ’­æ”¾
        
        è¿™ä¸ªå‡½æ•°å°è£…äº†å®Œæ•´çš„æ™ºèƒ½å¯¹è¯æµç¨‹ï¼š
        1. ä½¿ç”¨LLMè·å–AIå›ç­”
        2. å°†å›ç­”è½¬æ¢ä¸ºè¯­éŸ³å¹¶æ’­æ”¾/ä¿å­˜
        
        Args:
            prompt: ç”¨æˆ·é—®é¢˜/æç¤ºè¯
            llm_provider: LLMæä¾›å•†åç§°ï¼Œé»˜è®¤"alibaba"
            llm_model: LLMæ¨¡å‹åç§°ï¼Œé»˜è®¤"qwen-turbo"
            tts_provider: TTSæä¾›å•†åç§°ï¼Œé»˜è®¤"alibaba"
            tts_model: TTSæ¨¡å‹åç§°ï¼Œé»˜è®¤"sambert-zhichu-v1"
            tts_mode: TTSæ¨¡å¼ ("speaker", "file", "stream")ï¼Œé»˜è®¤"speaker"
            use_context: æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡å¯¹è¯ï¼Œé»˜è®¤False
            session_id: ä¼šè¯IDï¼Œå¯ç”¨ä¸Šä¸‹æ–‡æ—¶ä½¿ç”¨
            stream_chat: æ˜¯å¦ä½¿ç”¨æµå¼LLMè¾“å‡ºï¼Œé»˜è®¤False
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œé»˜è®¤False
            **kwargs: å…¶ä»–å‚æ•°
                - LLMå‚æ•°: temperature, max_tokens, top_pç­‰
                - TTSå‚æ•°: voice, sample_rate, output_fileç­‰
                
        Returns:
            åŒ…å«LLMå›ç­”å’ŒTTSç»“æœçš„å­—å…¸
            
        Examples:
            # åŸºç¡€æ™ºèƒ½å¯¹è¯
            result = sdk.smart_chat("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
            
            # ä¿å­˜è¯­éŸ³åˆ°æ–‡ä»¶
            result = sdk.smart_chat(
                "è®²ä¸ªæ•…äº‹", 
                tts_mode="file",
                output_file="story.mp3"
            )
            
            # ä¸Šä¸‹æ–‡å¯¹è¯
            sdk.smart_chat("æˆ‘å«å¼ ä¸‰", use_context=True)
            result = sdk.smart_chat("æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ", use_context=True)
            
            # æŒ‡å®šæ¨¡å‹å’ŒéŸ³è‰²
            result = sdk.smart_chat(
                "ç”¨æ¸©æŸ”çš„å£°éŸ³è¯´è¯",
                llm_model="qwen-plus",
                tts_model="cosyvoice-v1",
                voice="longxiaoxia"
            )
            
            # å¼‚æ­¥è°ƒç”¨
            result = await sdk.smart_chat("ä½ å¥½", async_mode=True)
        """
        
        # åˆ†ç¦»LLMå’ŒTTSå‚æ•°
        llm_kwargs = {}
        tts_kwargs = {}
        
        # LLMç›¸å…³å‚æ•°
        llm_params = ['temperature', 'max_tokens', 'top_p', 'top_k', 'repetition_penalty']
        for param in llm_params:
            if param in kwargs:
                llm_kwargs[param] = kwargs.pop(param)
        
        # TTSç›¸å…³å‚æ•°
        tts_params = ['voice', 'sample_rate', 'format', 'output_file']
        for param in tts_params:
            if param in kwargs:
                tts_kwargs[param] = kwargs.pop(param)
        
        # æ·»åŠ TTSæ¨¡å‹å‚æ•°
        tts_kwargs['model'] = tts_model
        
        if async_mode:
            return self.smart_chat_handler.handle_async(
                prompt, llm_provider, llm_model, tts_provider, tts_mode,
                use_context, session_id, stream_chat, llm_kwargs, tts_kwargs
            )
        else:
            return self.smart_chat_handler.handle_sync(
                prompt, llm_provider, llm_model, tts_provider, tts_mode,
                use_context, session_id, stream_chat, llm_kwargs, tts_kwargs
            )

    def smart_multimodal_chat(self,
                             prompt: str,
                             image_path: str = None,
                             video_path: str = None,
                             image_paths: List[str] = None,
                             multimodal_provider: str = "alibaba",
                             multimodal_model: str = "qwen-vl-max-latest",
                             tts_provider: str = "alibaba",
                             tts_model: str = "sambert-zhichu-v1",
                             tts_mode: str = "speaker",
                             stream_output: bool = False,
                             realtime_tts: bool = True,
                             async_mode: bool = False,
                             **kwargs) -> Dict[str, Any]:
        """
        ğŸ¤–ğŸ¥ğŸ”Š å¤šæ¨¡æ€æ™ºèƒ½å¯¹è¯ - å›¾åƒ/è§†é¢‘ç†è§£ + æµå¼è¾“å‡º + å®æ—¶è¯­éŸ³æ’­æ”¾
        
        è¿™ä¸ªå‡½æ•°å°è£…äº†å®Œæ•´çš„å¤šæ¨¡æ€æ™ºèƒ½å¯¹è¯æµç¨‹ï¼š
        1. ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹ç†è§£å›¾åƒ/è§†é¢‘å†…å®¹
        2. æµå¼è¾“å‡ºAIçš„ç†è§£å’Œå›ç­”
        3. å®æ—¶å°†å›ç­”è½¬æ¢ä¸ºè¯­éŸ³å¹¶æ’­æ”¾
        
        Args:
            prompt: ç”¨æˆ·é—®é¢˜/æç¤ºè¯
            image_path: å•å¼ å›¾åƒè·¯å¾„æˆ–URL
            video_path: è§†é¢‘è·¯å¾„æˆ–URL
            image_paths: å¤šå¼ å›¾åƒè·¯å¾„æˆ–URLåˆ—è¡¨
            multimodal_provider: å¤šæ¨¡æ€æä¾›å•†åç§°ï¼Œé»˜è®¤"alibaba"
            multimodal_model: å¤šæ¨¡æ€æ¨¡å‹åç§°ï¼Œé»˜è®¤"qwen-vl-max-latest"
            tts_provider: TTSæä¾›å•†åç§°ï¼Œé»˜è®¤"alibaba"
            tts_model: TTSæ¨¡å‹åç§°ï¼Œé»˜è®¤"sambert-zhichu-v1"
            tts_mode: TTSæ¨¡å¼ ("speaker", "file")ï¼Œé»˜è®¤"speaker"
            stream_output: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡ºï¼Œé»˜è®¤True
            realtime_tts: æ˜¯å¦å®æ—¶è¯­éŸ³æ’­æ”¾ï¼Œé»˜è®¤True
            async_mode: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œé»˜è®¤False
            **kwargs: å…¶ä»–å‚æ•°
                - å¤šæ¨¡æ€å‚æ•°: temperature, max_tokensç­‰
                - TTSå‚æ•°: voice, sample_rate, output_fileç­‰
                
        Returns:
            åŒ…å«å¤šæ¨¡æ€ç†è§£ç»“æœå’ŒTTSç»“æœçš„å­—å…¸
            
        Examples:
            # åŸºç¡€å›¾åƒç†è§£å¯¹è¯
            result = sdk.smart_multimodal_chat(
                "è¯·æè¿°è¿™å¼ å›¾ç‰‡",
                image_path="image.jpg"
            )
            
            # è§†é¢‘åˆ†æå¯¹è¯
            result = sdk.smart_multimodal_chat(
                "åˆ†æè¿™ä¸ªè§†é¢‘çš„å†…å®¹",
                video_path="video.mp4"
            )
            
            # å¤šå›¾åƒæ¯”è¾ƒå¯¹è¯
            result = sdk.smart_multimodal_chat(
                "æ¯”è¾ƒè¿™äº›å›¾ç‰‡çš„å·®å¼‚",
                image_paths=["img1.jpg", "img2.jpg"]
            )
            
            # ä¿å­˜è¯­éŸ³åˆ°æ–‡ä»¶
            result = sdk.smart_multimodal_chat(
                "è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡",
                image_path="image.jpg",
                tts_mode="file",
                output_file="analysis.mp3"
            )
            
            # å¼‚æ­¥è°ƒç”¨
            result = await sdk.smart_multimodal_chat(
                "æè¿°å›¾ç‰‡å†…å®¹",
                image_path="image.jpg",
                async_mode=True
            )
        """
        
        # åˆ†ç¦»å¤šæ¨¡æ€å’ŒTTSå‚æ•°
        multimodal_kwargs = {}
        tts_kwargs = {}
        
        # å¤šæ¨¡æ€ç›¸å…³å‚æ•°
        multimodal_params = ['temperature', 'max_tokens', 'top_p', 'fps', 'use_openai_format']
        for param in multimodal_params:
            if param in kwargs:
                multimodal_kwargs[param] = kwargs.pop(param)
        
        # TTSç›¸å…³å‚æ•°
        tts_params = ['voice', 'sample_rate', 'format', 'output_file']
        for param in tts_params:
            if param in kwargs:
                tts_kwargs[param] = kwargs.pop(param)
        
        # æ·»åŠ æ¨¡å‹å‚æ•°
        multimodal_kwargs['model'] = multimodal_model
        tts_kwargs['model'] = tts_model
        
        if async_mode:
            try:
                return self.smart_multimodal_chat_handler.handle_async(
                    prompt, image_path, video_path, image_paths,
                    multimodal_provider, tts_provider, tts_mode,
                    stream_output, realtime_tts, multimodal_kwargs, tts_kwargs
                )
            except Exception as e:
                print(f"âŒ å¼‚æ­¥å¤šæ¨¡æ€æ™ºèƒ½å¯¹è¯å‡ºç°å¼‚å¸¸: {e}")
                import traceback
                print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
                return {
                    'success': False,
                    'error': f"å¼‚æ­¥å¤šæ¨¡æ€æ™ºèƒ½å¯¹è¯å¼‚å¸¸: {str(e)}",
                    'answer': '',
                    'mode': 'error',
                    'media_info': 'error'
                }
        else:
            try:
                result = self.smart_multimodal_chat_handler.handle_sync(
                    prompt, image_path, video_path, image_paths,
                    multimodal_provider, tts_provider, tts_mode,
                    stream_output, realtime_tts, multimodal_kwargs, tts_kwargs
                )
                return result
            except Exception as e:
                print(f"âŒ å¤šæ¨¡æ€æ™ºèƒ½å¯¹è¯å‡ºç°å¼‚å¸¸: {e}")
                import traceback
                print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
                return {
                    'success': False,
                    'error': f"å¤šæ¨¡æ€æ™ºèƒ½å¯¹è¯å¼‚å¸¸: {str(e)}",
                    'answer': '',
                    'mode': 'error',
                    'media_info': 'error'
                }

    def smart_voice_chat(self,
                        duration: int = 5,
                        llm_provider: str = "alibaba",
                        llm_model: str = "qwen-turbo",
                        tts_provider: str = "alibaba",
                        tts_model: str = "sambert-zhichu-v1",
                        use_context: bool = True,
                        session_id: str = "voice_chat",
                        continue_conversation: bool = True,
                        activation_phrase: str = "ä½ å¥½åŠ©æ‰‹",
                        activate_once: bool = True,
                        end_phrase: str = "ç»“æŸå¯¹è¯",
                        silence_timeout: float = 2.0,
                        verbose: bool = False,
                        **kwargs) -> Dict[str, Any]:
        """
        ğŸ™ï¸ğŸ¤–ğŸ”Š æ™ºèƒ½è¯­éŸ³å¯¹è¯ - å®æ—¶ASR + LLM + å®æ—¶TTS
        
        é€šè¿‡éº¦å…‹é£æ•è·ç”¨æˆ·è¯­éŸ³ï¼Œå®æ—¶è½¬æ¢ä¸ºæ–‡æœ¬ï¼Œå‘é€ç»™LLMï¼Œå¹¶å®æ—¶æ’­æ”¾AIå›å¤ã€‚
        
        Args:
            duration: æ¯æ¬¡å½•éŸ³çš„æœ€å¤§ç§’æ•°ï¼Œé»˜è®¤5ç§’
            llm_provider: LLMæä¾›å•†åç§°ï¼Œé»˜è®¤"alibaba"
            llm_model: LLMæ¨¡å‹åç§°ï¼Œé»˜è®¤"qwen-turbo"
            tts_provider: TTSæä¾›å•†åç§°ï¼Œé»˜è®¤"alibaba"
            tts_model: TTSæ¨¡å‹åç§°ï¼Œé»˜è®¤"sambert-zhichu-v1"
            use_context: æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡å¯¹è¯ï¼Œé»˜è®¤True
            session_id: ä¼šè¯IDï¼Œé»˜è®¤"voice_chat"
            continue_conversation: æ˜¯å¦æŒç»­å¯¹è¯ï¼Œé»˜è®¤True
            activation_phrase: æ¿€æ´»çŸ­è¯­ï¼Œè¯´å‡ºæ­¤çŸ­è¯­å¼€å§‹å¯¹è¯ï¼Œä¸ºNoneæ—¶ä¸éœ€è¦æ¿€æ´»çŸ­è¯­
            activate_once: æ˜¯å¦åªéœ€æ¿€æ´»ä¸€æ¬¡ï¼Œé»˜è®¤Trueï¼Œå³é¦–æ¬¡å¯åŠ¨å¯¹è¯æ—¶éœ€è¦æ¿€æ´»ï¼Œåç»­å¯¹è¯ä¸éœ€è¦
            end_phrase: ç»“æŸå¯¹è¯çš„çŸ­è¯­ï¼Œé»˜è®¤"ç»“æŸå¯¹è¯"
            silence_timeout: é™éŸ³è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œæ£€æµ‹åˆ°é™éŸ³è¿™ä¹ˆé•¿æ—¶é—´åè®¤ä¸ºè¯­éŸ³è¾“å…¥ç»“æŸ
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—ï¼Œé»˜è®¤False
            **kwargs: å…¶ä»–å‚æ•°ï¼ŒåŒ…æ‹¬LLMå’ŒTTSçš„å‚æ•°
            
        Returns:
            Dict[str, Any]: å¯¹è¯ç»“æœä¿¡æ¯
            
        Example:
            # å¯åŠ¨å®æ—¶è¯­éŸ³å¯¹è¯
            sdk.smart_voice_chat()
            
            # è‡ªå®šä¹‰å‚æ•°
            sdk.smart_voice_chat(
                llm_model="qwen-plus",
                tts_model="cosyvoice-v1",
                voice="longxiaochun",
                activation_phrase="ä½ å¥½åŠ©æ‰‹"
            )
        """
        return self.smart_voice_chat_handler.handle_voice_chat(
            duration=duration,
            llm_provider=llm_provider,
            llm_model=llm_model,
            tts_provider=tts_provider,
            tts_model=tts_model,
            use_context=use_context,
            session_id=session_id,
            continue_conversation=continue_conversation,
            activation_phrase=activation_phrase,
            activate_once=activate_once,
            end_phrase=end_phrase,
            silence_timeout=silence_timeout,
            verbose=verbose,
            **kwargs
        )

    def smart_multimodal_voice_chat(self,
                              image_path: str = None,
                              video_path: str = None,
                              image_paths: List[str] = None,
                              duration: int = 5,
                              llm_provider: str = "alibaba",
                              llm_model: str = "qwen-vl-max-latest",
                              tts_provider: str = "alibaba",
                              tts_model: str = "sambert-zhichu-v1",
                              use_context: bool = True,
                              session_id: str = "multimodal_voice_chat",
                              continue_conversation: bool = True,
                              activation_phrase: str = "ä½ å¥½åŠ©æ‰‹",
                              activate_once: bool = True,
                              end_phrase: str = "ç»“æŸå¯¹è¯",
                              silence_timeout: float = 2.0,
                              verbose: bool = False,
                              **kwargs) -> Dict[str, Any]:
        """
        ğŸ™ï¸ğŸ–¼ï¸ğŸ”Š æ™ºèƒ½å¤šæ¨¡æ€è¯­éŸ³å¯¹è¯ - å®æ—¶ASR + å¤šæ¨¡æ€LLM + å®æ—¶TTS
        
        å°†è¯­éŸ³è¯†åˆ«ã€å¤šæ¨¡æ€å¤§æ¨¡å‹å’Œè¯­éŸ³åˆæˆç»“åˆåœ¨ä¸€èµ·ï¼Œå¯ä»¥å¯¹å›¾åƒã€è§†é¢‘è¿›è¡Œè¯­éŸ³æé—®å¹¶è·å¾—è¯­éŸ³å›ç­”ã€‚
        
        Args:
            image_path: å›¾åƒè·¯å¾„ï¼Œå¯ä»¥æ˜¯æœ¬åœ°æ–‡ä»¶æˆ–URL
            video_path: è§†é¢‘è·¯å¾„ï¼Œå¯ä»¥æ˜¯æœ¬åœ°æ–‡ä»¶æˆ–URL
            image_paths: å¤šå›¾åƒè·¯å¾„åˆ—è¡¨ï¼Œç”¨äºæ¯”è¾ƒå¤šå¼ å›¾åƒ
            duration: æ¯æ¬¡å½•éŸ³çš„æœ€å¤§ç§’æ•°ï¼Œé»˜è®¤5ç§’
            llm_provider: LLMæä¾›å•†åç§°ï¼Œé»˜è®¤"alibaba"
            llm_model: LLMæ¨¡å‹åç§°ï¼Œé»˜è®¤"qwen-vl-max-latest"
            tts_provider: TTSæä¾›å•†åç§°ï¼Œé»˜è®¤"alibaba"
            tts_model: TTSæ¨¡å‹åç§°ï¼Œé»˜è®¤"sambert-zhichu-v1"
            use_context: æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡å¯¹è¯ï¼Œé»˜è®¤True
            session_id: ä¼šè¯IDï¼Œé»˜è®¤"multimodal_voice_chat"
            continue_conversation: æ˜¯å¦æŒç»­å¯¹è¯ï¼Œé»˜è®¤True
            activation_phrase: æ¿€æ´»çŸ­è¯­ï¼Œè¯´å‡ºæ­¤çŸ­è¯­å¼€å§‹å¯¹è¯ï¼Œä¸ºNoneæ—¶ä¸éœ€è¦æ¿€æ´»çŸ­è¯­
            activate_once: æ˜¯å¦åªéœ€æ¿€æ´»ä¸€æ¬¡ï¼Œé»˜è®¤Trueï¼Œå³é¦–æ¬¡å¯åŠ¨å¯¹è¯æ—¶éœ€è¦æ¿€æ´»ï¼Œåç»­å¯¹è¯ä¸éœ€è¦
            end_phrase: ç»“æŸå¯¹è¯çš„çŸ­è¯­ï¼Œé»˜è®¤"ç»“æŸå¯¹è¯"
            silence_timeout: é™éŸ³è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œæ£€æµ‹åˆ°é™éŸ³è¿™ä¹ˆé•¿æ—¶é—´åè®¤ä¸ºè¯­éŸ³è¾“å…¥ç»“æŸ
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—ï¼Œé»˜è®¤False
            **kwargs: å…¶ä»–å‚æ•°ï¼ŒåŒ…æ‹¬LLMå’ŒTTSçš„å‚æ•°
            
        Returns:
            Dict[str, Any]: å¯¹è¯ç»“æœä¿¡æ¯
            
        Example:
            # å¯åŠ¨å¤šæ¨¡æ€è¯­éŸ³å¯¹è¯ï¼ˆå›¾åƒï¼‰
            sdk.smart_multimodal_voice_chat(image_path="path/to/image.jpg")
            
            # å¯åŠ¨å¤šæ¨¡æ€è¯­éŸ³å¯¹è¯ï¼ˆè§†é¢‘ï¼‰
            sdk.smart_multimodal_voice_chat(video_path="path/to/video.mp4")
            
            # å¯åŠ¨å¤šæ¨¡æ€è¯­éŸ³å¯¹è¯ï¼ˆå¤šå›¾åƒæ¯”è¾ƒï¼‰
            sdk.smart_multimodal_voice_chat(
                image_paths=["path/to/image1.jpg", "path/to/image2.jpg"],
                llm_model="qwen-vl-max",
                tts_model="sambert-zhichu-v1",
                voice="zhizhe",
                activation_phrase="ä½ å¥½åŠ©æ‰‹"
            )
        """
        return self.smart_multimodal_voice_chat_handler.handle_multimodal_voice_chat(
            image_path=image_path,
            video_path=video_path,
            image_paths=image_paths,
            duration=duration,
            llm_provider=llm_provider,
            llm_model=llm_model,
            tts_provider=tts_provider,
            tts_model=tts_model,
            use_context=use_context,
            session_id=session_id,
            continue_conversation=continue_conversation,
            activation_phrase=activation_phrase,
            activate_once=activate_once,
            end_phrase=end_phrase,
            silence_timeout=silence_timeout,
            verbose=verbose,
            **kwargs
        )
        
    # ğŸ› ï¸ ä¾¿æ·å·¥å…·æ–¹æ³•
    def get_conversation_history(self, session_id: str = None) -> List[Dict[str, str]]:
        """
        ğŸ“œ è·å–ä¼šè¯å†å²è®°å½•
        
        Args:
            session_id: ä¼šè¯IDï¼Œä¸æä¾›åˆ™è¿”å›å…¨å±€å†å²
            
        Returns:
            ä¼šè¯å†å²åˆ—è¡¨
        """
        return self.chat_handler.get_conversation_history(session_id)

    def clear_conversation_history(self, session_id: str = None):
        """
        ğŸ—‘ï¸ æ¸…ç©ºä¼šè¯å†å²è®°å½•
        
        Args:
            session_id: ä¼šè¯IDï¼Œä¸æä¾›åˆ™æ¸…ç©ºå…¨å±€å†å²
        """
        self.chat_handler.clear_conversation_history(session_id)

    def set_conversation_history(self, history: List[Dict[str, str]], session_id: str = None):
        """
        ğŸ“ è®¾ç½®ä¼šè¯å†å²è®°å½•
        
        Args:
            history: ä¼šè¯å†å²åˆ—è¡¨
            session_id: ä¼šè¯IDï¼Œä¸æä¾›åˆ™è®¾ç½®å…¨å±€å†å²
        """
        self.chat_handler.set_conversation_history(history, session_id)

    # ğŸ‘¥ ä¼šè¯ç®¡ç†
    def create_session(self, session_id: str = None, max_history: int = None, 
                      system_prompt: str = None) -> ChatSession:
        """
        â• åˆ›å»ºæ–°çš„å¯¹è¯ä¼šè¯
        
        Args:
            session_id: ä¼šè¯IDï¼Œä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆ
            max_history: æœ€å¤§å†å²è®°å½•æ•°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®å€¼
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            
        Returns:
            ä¼šè¯å¯¹è±¡
        """
        return self.chat_handler.create_session(session_id, max_history, system_prompt)

    def get_session(self, session_id: str) -> ChatSession:
        """
        ğŸ“‹ è·å–æŒ‡å®šä¼šè¯
        
        Args:
            session_id: ä¼šè¯ID
            
        Returns:
            ä¼šè¯å¯¹è±¡
        """
        return self.chat_handler.get_session(session_id)

    def delete_session(self, session_id: str) -> bool:
        """
        ğŸ—‘ï¸ åˆ é™¤æŒ‡å®šä¼šè¯
        
        Args:
            session_id: ä¼šè¯ID
            
        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        return self.chat_handler.delete_session(session_id)

    def list_sessions(self):
        """
        ğŸ“‹ åˆ—å‡ºæ‰€æœ‰ä¼šè¯
        
        Returns:
            ä¼šè¯IDåˆ—è¡¨
        """
        return self.chat_handler.list_sessions()

    # ğŸ“Š é…ç½®å’Œä¿¡æ¯æŸ¥è¯¢
    def get_available_providers(self) -> Dict[str, Dict[str, Any]]:
        """
        ğŸ“‹ è·å–å¯ç”¨çš„æä¾›å•†ä¿¡æ¯
        
        Returns:
            æä¾›å•†ä¿¡æ¯å­—å…¸
        """
        return self.config.get('providers', {})

    def get_provider_models(self, provider: str) -> Dict[str, Any]:
        """
        ğŸ“‹ è·å–æŒ‡å®šæä¾›å•†çš„æ¨¡å‹ä¿¡æ¯
        
        Args:
            provider: æä¾›å•†åç§°
            
        Returns:
            æ¨¡å‹ä¿¡æ¯å­—å…¸
        """
        providers = self.config.get('providers', {})
        if provider not in providers:
            raise ValueError(f"æœªæ‰¾åˆ°æä¾›å•†: {provider}")
        
        return providers[provider].get('models', {})


    def get_config(self) -> Dict[str, Any]:
        """
        ğŸ“‹ è·å–å½“å‰é…ç½®
        
        Returns:
            é…ç½®å­—å…¸
        """
        return self.config.copy()

    def update_config(self, new_config: Dict[str, Any]):
        """
        ğŸ”„ æ›´æ–°é…ç½®
        
        Args:
            new_config: æ–°é…ç½®å­—å…¸
        """
        self.config.update(new_config)
        # é‡æ–°åˆå§‹åŒ–å¤„ç†å™¨
        self.chat_handler = ChatHandler(self.config)
        self.asr_handler = ASRHandler(self.config)
        self.tts_handler = TTSHandler(self.config)
        self.multimodal_handler = MultiModalHandler(self.config)
        self.smart_chat_handler = SmartChatHandler(self)
        self.smart_multimodal_chat_handler = SmartMultiModalChatHandler(self)
        self.smart_voice_chat_handler = SmartVoiceChatHandler(self)
        self.smart_multimodal_voice_chat_handler = SmartMultiModalVoiceChatHandler(self)

# å¯¼å‡ºä¸»è¦ç±»å’Œå¼‚å¸¸
__all__ = ['AISDK', 'AISDKException', 'ValidationException', 'ConfigException'] 